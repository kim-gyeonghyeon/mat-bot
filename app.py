import streamlit as st
import os
import google.generativeai as genai

# --- [ì„¤ì •] ---
GOOGLE_API_KEY = "AIzaSyA8AeFMqW3vsuFahBwDgntk5ERwz0xwoo8"
genai.configure(api_key=GOOGLE_API_KEY)
DATA_FILE = "rules.txt"
# --------------

st.set_page_config(page_title="ì‚¬ë‚´ê·œì • ì±—ë´‡", page_icon="ğŸ¤–")
st.title("ğŸ“‚ ì— ì—ì´í‹°í”ŒëŸ¬ìŠ¤ ì‚¬ë‚´ê·œì • ì±—ë´‡")

def get_rules():
    path = os.path.join(os.path.dirname(os.path.abspath(__file__)), DATA_FILE)
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            return f.read()
    return None

rules_text = get_rules()

# ëª¨ë¸ ì—°ê²° í•¨ìˆ˜: 404 ì—ëŸ¬ë¥¼ ì¡ê¸° ìœ„í•´ ì—¬ëŸ¬ ì´ë¦„ì„ ì‹œë„í•©ë‹ˆë‹¤.
def load_model():
    model_names = [
        'gemini-1.5-flash',
        'gemini-1.5-flash-latest',
        'models/gemini-1.5-flash',
        'gemini-pro'
    ]
    for name in model_names:
        try:
            m = genai.GenerativeModel(name)
            # ì‹¤ì œë¡œ ì‘ë™í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸ í˜¸ì¶œ
            m.generate_content("test")
            return m
        except:
            continue
    return None

if rules_text:
    if "chat_model" not in st.session_state:
        st.session_state.chat_model = load_model()

    if st.session_state.chat_model:
        st.success("âœ… ê·œì • í™•ì¸ ì™„ë£Œ! ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")
    else:
        st.error("âŒ í˜„ì¬ êµ¬ê¸€ AI ëª¨ë¸ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

    if "messages" not in st.session_state:
        st.session_state.messages = []

    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    if user_input := st.chat_input("ê·œì •ì— ëŒ€í•´ ë¬¼ì–´ë³´ì„¸ìš”"):
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        if st.session_state.chat_model:
            with st.chat_message("assistant"):
                with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                    prompt = f"ë‹¤ìŒ ê·œì •ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µí•˜ì„¸ìš”:\n{rules_text}\n\nì§ˆë¬¸: {user_input}"
                    try:
                        response = st.session_state.chat_model.generate_content(prompt)
                        st.markdown(response.text)
                        st.session_state.messages.append({"role": "assistant", "content": response.text})
                    except Exception as e:
                        st.error(f"ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
        else:
            st.error("ëª¨ë¸ì´ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
else:
    st.error(f"'{DATA_FILE}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

