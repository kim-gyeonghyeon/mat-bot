import streamlit as st
import os
import google.generativeai as genai

# --- [ì„¤ì •] ---
GOOGLE_API_KEY = "AIzaSyCdyr7CbuHNIff8PWYWRNwcw4hSVf6FWok"
genai.configure(api_key=GOOGLE_API_KEY)
DATA_FILE = "rules.txt"
# --------------

st.set_page_config(page_title="ì‚¬ë‚´ê·œì • ì±—ë´‡", page_icon="ğŸ¤–")
st.title("ğŸ“‚ ì— ì—ì´í‹°í”ŒëŸ¬ìŠ¤ ì‚¬ë‚´ê·œì • ì±—ë´‡")

def get_rules():
    # í˜„ì¬ í´ë”ì—ì„œ íŒŒì¼ì„ í™•ì‹¤íˆ ì°¾ê¸° ìœ„í•´ ê²½ë¡œ ì¬ì„¤ì •
    path = os.path.join(os.path.dirname(os.path.abspath(__file__)), DATA_FILE)
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            return f.read()
    return None

rules_text = get_rules()

if rules_text:
    # í•µì‹¬ ìˆ˜ì •: ëª¨ë¸ ì´ë¦„ì—ì„œ 'models/'ë¥¼ ë¹¼ê±°ë‚˜ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •
    # ë§Œì•½ 'gemini-1.5-flash'ê°€ ì•ˆë˜ë©´ 'gemini-pro'ë¡œ ìë™ ì „í™˜ë˜ê²Œ êµ¬ì„±
    try:
        model = genai.GenerativeModel('models/gemini-1.5-flash')
    except:
        model = genai.GenerativeModel('gemini-pro')
    
    st.success("âœ… ê·œì • í™•ì¸ ì™„ë£Œ! ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")

    if "messages" not in st.session_state:
        st.session_state.messages = []

    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    if user_input := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        with st.chat_message("assistant"):
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                prompt = f"ë‹¤ìŒ ê·œì •ì„ ì°¸ê³ í•´ ë‹µë³€í•´ì¤˜:\n{rules_text}\n\nì§ˆë¬¸: {user_input}"
                
                try:
                    # ì‘ë‹µ ìƒì„± ì‹œ ë°œìƒí•  ìˆ˜ ìˆëŠ” 404 ì—ëŸ¬ë¥¼ ì¡ê¸° ìœ„í•œ ì˜ˆì™¸ ì²˜ë¦¬
                    response = model.generate_content(prompt)
                    st.markdown(response.text)
                    st.session_state.messages.append({"role": "assistant", "content": response.text})
                except Exception as e:
                    # ì—ëŸ¬ê°€ ë‚˜ë©´ ëª¨ë¸ ì´ë¦„ì„ ë°”ê¿”ì„œ í•œ ë²ˆ ë” ì‹œë„ (ìµœí›„ì˜ ìˆ˜ë‹¨)
                    try:
                        alt_model = genai.GenerativeModel('gemini-pro')
                        response = alt_model.generate_content(prompt)
                        st.markdown(response.text)
                        st.session_state.messages.append({"role": "assistant", "content": response.text})
                    except:
                        st.error(f"ëª¨ë¸ ì—°ê²° ì‹¤íŒ¨. API í‚¤ ë˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ì„ í™•ì¸í•´ì£¼ì„¸ìš”: {e}")
else:
    st.error(f"'{DATA_FILE}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    st.info(f"í˜„ì¬ ìœ„ì¹˜: {os.path.dirname(os.path.abspath(__file__))}\nì—¬ê¸°ì— rules.txtê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
